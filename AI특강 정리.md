### AI - 특강



## Foundation 모델

- 새로운 인공지능 시대

- 파운데이션 모델이란?

- 파운데이션 모델의 등장까지...



## Foundation 모델적 사고

- 파운데이션 모델 활용

- 파운데이션 시대의 문제 접근법

- 파운데이션 모델 활용 예시



### 새로운 인공지능의 시대!

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-14-04-42-image.png)

- 응용사례

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-14-05-51-image.png)



![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-14-08-24-image.png)

모듈별 Unit test도 자동화 가능하다

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-14-08-54-image.png)



![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-14-09-28-image.png)



![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-14-11-39-image.png)



![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-14-12-01-image.png)



## 파운데이션 모델이란??

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-14-13-15-image.png)

- 모델이란? 뉴럴네트워크를 통해 함수형태로 만든것

- 기계학습이 뉴럴네트워크로만 만들어져야하나?  AGI란?

- 이상적인 기계학습 모델이란?
  
  - 이 세상의 모든 데이터를 기억하고 있는 모델 + 이후 발생될 모든 정보를 가짐
  
  - 내가 얻고 싶은 답과 유사한 답이 이미 DB에 저장되어있음 -> 극도로 고도화된 검색엔진
    -> 현실적으로 불가능함

- 현실적인 기계학습 모델
  
  - 모델 파라미터에 데이터를 패턴화하여 압축
  
  - 추가적으로 데이터 학습

- 따라서 파운데이션 모델이란??
  
  - 대규모 데이터를 폭넓게 먼저 학습한 후, 다양한 문제에 빠르게 적응할 수 있는 범용 대형 AI 모델

- 미국 스탠포드 대학 사람 중심 AI연구소에서 2021년 출간된 보고서 [1]에서 새로운 범주로 구분을 시작
  
  ![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-14-18-05-image.png)

- 굳이 기존 딥러닝 모델과의 차별점은?

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-14-18-48-image.png)

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-14-20-09-image.png)

- 대규모 학습에 유리한, 데이터 수집이 쉬운 형태로 진화중![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-14-22-37-image.png)

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-14-25-14-image.png)

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-14-27-37-image.png)

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-14-28-45-image.png)



![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-14-31-26-image.png)

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-14-33-57-image.png)

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-14-34-16-image.png)

### 파운데이션 모델적 사고

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-14-35-40-image.png)

- 어떻게 활용될까?

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-14-36-14-image.png)



![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-14-38-10-image.png)

1. 다른 방식으로 어떻게 이용할 수 있을지 고민하자!

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-14-41-15-image.png)

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-14-41-43-image.png)

예시

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-14-42-12-image.png)

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-14-42-59-image.png)

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-14-44-35-image.png)

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-14-46-11-image.png)

- Zero-shot : 충분히 똑똑한 모델일경우에 간단하고 빠름/ 하지만 사전학습 되지않은 경우 정확도가 떨어질 수 있음

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-14-47-15-image.png)

- 예시의 개수 늘릴수록 성능 up / 사전학습된 모델은 그대로, 입력만 바꾼다.

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-14-47-58-image.png)

- zero, few-shot이 안될경우에 파라미터를 바꿔 추가학습을 진행 -> 성능향상을 기대할 수 있음

- 학습에 대한 이해가 필요함 -> 난이도 높음(역전파가 뭔가요)

- 리소스와 시간 소모가 크다지만 사전학습 보다는 비용이 낮다.

- 개인화 모델 구현에 Fine-tuning기법이 필수

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-14-50-30-image.png)

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-15-03-37-image.png)

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-15-07-07-image.png)

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-15-09-47-image.png)

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-15-10-00-image.png)

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-15-10-13-image.png)

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-15-10-29-image.png)

Qwen을 기반으로 연구하는 대기업이 많음 -> 핫하다!

Mistral - 점점 한물가고있음

DeepSeek 

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-15-12-46-image.png)

한국어 정식지원이기에 프로젝트에 활용하면 좋다!



![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-15-14-16-image.png)

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-15-15-23-image.png)

암묵적으로 고성능 모델 훔쳐씀 ㅋㅋ

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-15-16-23-image.png)

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-15-18-01-image.png)

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-15-18-19-image.png)

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-15-22-12-image.png)

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-15-22-27-image.png)

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-15-22-49-image.png)

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-15-23-09-image.png)

- 미드저니가 예술작품으로 상을 타버림;; - 세부묘사나 품질이 높음

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-15-25-01-image.png)

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-15-25-53-image.png)

텍스트 이미지화 능력이 뛰어나다!!



![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-15-27-19-image.png)

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-15-28-59-image.png)

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-15-29-29-image.png)

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-15-30-24-image.png)

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-15-30-33-image.png)

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-15-31-08-image.png)

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-15-31-36-image.png)





![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-15-32-37-image.png)

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-15-32-54-image.png)

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-15-33-04-image.png)

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-15-33-17-image.png)

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-15-34-29-image.png)

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-15-34-46-image.png)

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-15-35-00-image.png)

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-15-35-24-image.png)

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-15-36-35-image.png)

도메인/이미지쪽은 오픈소스가 많음 -> 아직 영리적인 서비스수준이 안됨

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-15-37-51-image.png)

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-15-38-00-image.png)

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-15-38-31-image.png)

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-15-39-09-image.png)

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-15-39-52-image.png)

사진이나 영상을 넣으면 3D로 복원해줌

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-15-40-40-image.png)

영상관련 서비스 -> 사람중심의 서비스가 많고 사람관련된 서비스가 많다 알아두자



![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-15-42-24-image.png)

음성인식 모델 - 녹음해서 자동 자막생성하기



![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-15-43-57-image.png)



![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-15-44-08-image.png)



![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-15-44-24-image.png)

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-15-45-21-image.png)

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-15-45-40-image.png)

소리의 중첩이 가능하다!



![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-15-46-12-image.png)

각종 오디오 모델이 통합됨 , 파이썬에서 라이브러리 호출로 바로 사용가능하다



![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-15-47-42-image.png)



![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-15-47-58-image.png)

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-15-48-07-image.png)

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-15-49-44-image.png)

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-15-50-17-image.png)

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-15-51-09-image.png)

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-15-52-14-image.png)

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-15-52-24-image.png)

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-15-53-51-image.png)

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-15-54-07-image.png)

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-15-54-23-image.png)



## 언어 파운데이션 모델

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-16-01-10-image.png)

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-16-01-23-image.png)

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-16-01-36-image.png)

4개 ( 대표적으로 3개)

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-16-02-24-image.png)

- 손실함수(리워드)



![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-16-02-43-image.png)

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-16-03-36-image.png)

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-16-03-59-image.png)

end2end를 지원하는 모델들이 여러개가 있는데 뉴럴네트워크가 그 중 하나이다. 근사를 잘 하는 친구이다.



![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-16-04-28-image.png)



![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-16-06-02-image.png)

구조를 하나하나 분해해서 알아보자



![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-16-06-17-image.png)

길이가 길어도 정보를 잃지 않는다!



![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-16-06-37-image.png)



인코더 디코더가 여러 layer로 이루어져있다



![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-16-07-02-image.png)

하나당 vocabulary라 한다.

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-16-08-06-image.png)

언어모델 처리의 기본 단위가 token



![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-16-08-30-image.png)

subword tokenization -> 통계에 따라 토큰을 구분



![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-16-09-01-image.png)

codebase를 하나의 토큰으로 보기보다는 code / base 각각 많이 쓰이는 단어이기에 각각 따로 토큰으로 본다.



![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-16-10-24-image.png)

토큰으로 정수화(indexing)되어서 대응되는 값이 임베드화하여 언어모델에 입력됨



토큰 임베딩은 멀티 모달 지원에 따라 방대한 양의 데이터가 난해해짐 -> 연구 대상

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-16-12-28-image.png)

확률분포(softmax)에 따라 해당되는 토큰의 단어가 튀어나옴

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-16-14-10-image.png)

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-16-14-18-image.png)

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-16-14-27-image.png)

### Attention이란??

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-16-15-38-image.png)

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-16-16-13-image.png)

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-16-16-46-image.png)



![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-16-18-53-image.png)

Multi-Head Attention(MHA)![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-16-27-13-image.png)

문장이 길어지면 self-attention의 의미가 여러가지가 될수 있음 - 가능성을 열어두는것

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-16-27-54-image.png)

문장 속 단어의 순서에 따라 의미가 달라지지만 attention은 그걸 고려하지 못함

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-16-30-43-image.png)

따라서 고려할 수 있는 정보를 추가함



![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-16-32-56-image.png)



![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-16-33-21-image.png)

인코더 - 입력단이 들어오면 입력단을 한번에 넣어서 문맥을 이해해놓음

디코더 - 입력 -> 출력 -> 출력한 단어를 다시 입력 -> 출력 -> 또 다시 출력한 단어를 다시 입력 반복



![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-16-35-31-image.png)

따라서 뒤에 다음 단어들은 가려줌



![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-16-36-07-image.png)

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-16-36-34-image.png)



![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-16-37-47-image.png)

입력 - 출력 - 다시 입력 - 출력 반복하는 방식을 Auto-regressive 방식이라고 한다.

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-16-38-59-image.png)



![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-16-39-32-image.png)



![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-16-40-26-image.png)

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-16-42-00-image.png)

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-16-42-42-image.png)

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-16-43-22-image.png)

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-16-43-48-image.png)

트랜스포머가 나오면서 그냥 모델 고정해놓고 돌리기만 하면됨

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-16-44-09-image.png)

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-16-44-29-image.png)

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-16-45-11-image.png)

데이터 인터넷에서 백과사전가지고 다음에 올 단어 맞추기 하면 요소3개가 다 필요없다



![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-16-45-39-image.png)

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-16-46-09-image.png)

그냥 데이터를 더 늘림 -> 성능 아주 좋아짐 zero-shot기능의 태동



![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-16-47-35-image.png)

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-16-47-44-image.png)

few-shot 기능 출현

자연어 코딩의 시작

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-16-50-04-image.png)

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-16-51-08-image.png)

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-16-51-55-image.png)

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-16-52-54-image.png)

사고의 절차를 주고 질문을하면 정확도가 확 오른다

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-16-53-42-image.png)

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-16-54-18-image.png)

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-16-56-08-image.png)

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-16-56-17-image.png)

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-16-57-04-image.png)

4차시



![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-17-02-55-image.png)



![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-17-03-13-image.png)



![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-17-04-03-image.png)

사고능력과 언어능력만으로는 현실 세계를 살기에 충분치 않다

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-17-05-09-image.png)

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-17-05-25-image.png)

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-17-07-43-image.png)



![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-17-08-01-image.png)

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-17-10-13-image.png)



![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-17-12-40-image.png)

encoder-only -> 들어오는 데이터 전체의 맥락을 파악하고 처리하는 데 더 유리

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-17-13-52-image.png)

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-17-14-30-image.png)

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-17-16-17-image.png)

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-17-16-56-image.png)

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-17-17-04-image.png)

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-17-20-55-image.png)

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-17-22-11-image.png)



갭을 역전파로, 데이터를 파라미터로 로스를 줄여가면서(역전파 - 최적화 / 최적화를 학습에도 사용가능한것)

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-17-25-43-image.png)

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-17-26-59-image.png)

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-17-27-09-image.png)

clip - 시각,청각등 감각정보를 인지하고 데이터화

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-17-27-35-image.png)

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-17-29-00-image.png)

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-17-29-27-image.png)

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-17-33-12-image.png)

상용 ai를 이용하여 (gpt) 라벨 데이터를 만들고 질의 생성

여러가지 질의 타입으로 학습 고도화

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-17-34-14-image.png)

- 모듈을 결합하는 패턴으로 변화함 -> 거대한 모델이라도 모듈화한다면 gpu리소스가 효율화된다.

- 요즘은 파운데이션 모델을 이용해서 대규모 학습 데이터셋을 만든다.

- 합성 데이터를 사용! -> 아주 좋은 기술

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-17-36-50-image.png)



![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-17-37-12-image.png)

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-17-39-05-image.png)

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-17-39-15-image.png)

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-17-40-30-image.png)

프롬프트 튜닝이 파인튜닝보다 훨씬 비용절약적

성능은 soso

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-17-42-42-image.png)

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-17-43-34-image.png)

현업에서 합성데이터/teacher-student학습 방법(일종의 전이 학습 방법) 두가지 많이씀!!

대형 모델을 작은모델로 압축하고 싶다! -> 이럴 때 사용

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-17-46-01-image.png)

모델이 만든 출력은 모델이 더 잘배운다 -> 모델끼리 알아듣는 말 함

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-17-47-42-image.png)

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-17-47-54-image.png)



![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-17-50-50-image.png)

ai에게 상상력까지 도입함



![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-17-51-56-image.png)

환각증세는 왜생길까?



![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-17-53-16-image.png)

![](C:\Users\SSAFY\AppData\Roaming\marktext\images\2025-05-07-17-55-07-image.png)


































































































































































































































































































